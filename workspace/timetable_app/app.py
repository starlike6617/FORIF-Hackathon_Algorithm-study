"""
Streamlit Timetable Wizard â€“ modalâ€‘free
â€¢ Robust column autoâ€‘detect (key/title/prof/time)
â€¢ ETâ€‘ratings merge â†’ userâ€‘weighted preference score
â€¢ Title search â‡’ ì—¬ëŸ¬ ë¶„ë°˜(í•™ìˆ˜ë²ˆí˜¸) ì¤‘ ì„ íƒ UI
â€¢ Simple schedule builder (no clash check yet)
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import streamlit as st
import pandas as pd
from datetime import datetime, date, time, timedelta
from itertools import product

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ì‹œê°„í‘œ ë§ˆë²•ì‚¬", page_icon="ğŸ§­", layout="centered")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Session init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ss = st.session_state
for key, default in {
    "groups":          [{"name": "ê·¸ë£¹ 1", "courses": []}],
    "required":        [],
    "constraints":     {"blocked_slots": set(), "must_lunch": False},
    "constraint_open": False,
    "catalog":         None,
    "weights":         {"ê³¼ì œ": 1.0, "ì¡°ëª¨ì„": 1.0, "ì„±ì ": 1.0},
    "search_df":       None,
    "search_target":   None,
}.items():
    ss.setdefault(key, default)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PALETTE = ["#FDE2E2", "#FFF5CC", "#DFF6F5", "#E8E4FF"]
DAYS = ["Mon", "Tue", "Wed", "Thu", "Fri"]
START, END = time(8, 0), time(22, 30)
RATING_COLS = ["ì„±ì  í›„í•¨", "ê³¼ì œ ì ìŒ", "ì¡°ëª¨ì„ ì ìŒ"]
KEY_COL = "ê°•ì¢ŒID"
NAME_COL = "êµê³¼ëª©ëª…"
PROF_COL = "êµê°•ì‚¬"
TIME_COL = "ì‹œê°„"
DISPLAY_COLS = [KEY_COL, NAME_COL, PROF_COL, TIME_COL] + RATING_COLS

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Catalog helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if KEY_COL not in df.columns:
        if "í•™ìˆ˜ë²ˆí˜¸-ìˆ˜ì—…ë²ˆí˜¸" in df.columns:
            df[KEY_COL] = df["í•™ìˆ˜ë²ˆí˜¸-ìˆ˜ì—…ë²ˆí˜¸"].astype(str)
        elif {"í•™ìˆ˜ë²ˆí˜¸", "ë¶„ë°˜"}.issubset(df.columns):
            df[KEY_COL] = df["í•™ìˆ˜ë²ˆí˜¸"].astype(str) + "-" + df["ë¶„ë°˜"].astype(str)
        elif "í•™ìˆ˜ë²ˆí˜¸" in df.columns:
            df[KEY_COL] = df["í•™ìˆ˜ë²ˆí˜¸"].astype(str)
        else:
            df[KEY_COL] = df.index.astype(str)

    rename_map = {
        NAME_COL: ["êµê³¼ëª©ëª…", "ê³¼ëª©ëª…", "title"],
        PROF_COL: ["êµê°•ì‚¬", "ë‹´ë‹¹êµìˆ˜", "êµìˆ˜ëª…", "professor"],
        TIME_COL: ["ì‹œê°„", "ìˆ˜ì—…ì‹œê°„", "ì‹œê°„í‘œ"],
    }
    for std, variants in rename_map.items():
        if std not in df.columns:
            for v in variants:
                if v in df.columns:
                    df = df.rename(columns={v: std}); break
        if std not in df.columns:
            df[std] = ""

    for col in RATING_COLS:
        if col not in df.columns:
            df[col] = pd.NA
    return df


def load_catalog(files):
    frames = []
    for f in files:
        try:
            if f.name.endswith("xlsx"):
                df = pd.read_excel(f, dtype=str)
            else:
                sep = "\t" if f.name.endswith("tsv") else ","
                df = pd.read_csv(f, sep=sep, dtype=str)
            frames.append(_normalize_columns(df))
        except Exception as e:
            st.error(f"{f.name} ì½ê¸° ì‹¤íŒ¨: {e}")
    if not frames:
        return
    ss.catalog = pd.concat(frames, ignore_index=True)
    update_preference_scores()
    st.success(f"âœ… í¸ëŒ {len(frames)}ê°œ, {len(ss.catalog)}í–‰ ë¶ˆëŸ¬ì˜´")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Metric â†’ preference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_metric_scores(df: pd.DataFrame) -> pd.DataFrame:
    """Flexible parsing: tolerate extra spaces/()% in column names."""
    df = df.copy()

    # helper to find matching column
    col_lookup = {}
    for col in df.columns:
        col_lookup[col.strip().replace(" ", "").replace("%", "")] = col

    def _get(col_alias: str):
        key = col_alias.replace(" ", "").replace("%", "")
        orig = col_lookup.get(key)
        if orig is None:
            df[col_alias] = 0  # create empty
            orig = col_alias
        df[orig] = pd.to_numeric(df[orig], errors="coerce").fillna(0)
        return df[orig]

    # ê³¼ì œ
    hw_none = _get("ê³¼ì œì—†ìŒ")
    hw_mid  = _get("ê³¼ì œë³´í†µ")
    df["ê³¼ì œ_score"] = (2*hw_none + 1*hw_mid) / 100
    # ì¡°ëª¨ì„
    team_none = _get("ì¡°ëª¨ì„ì—†ìŒ")
    team_mid  = _get("ì¡°ëª¨ì„ë³´í†µ")
    df["ì¡°ëª¨ì„_score"] = (2*team_none + 1*team_mid) / 100
    # ì„±ì 
    grade_easy = _get("ì„±ì ë„ˆê·¸ëŸ¬ì›€")
    grade_mid  = _get("ì„±ì ë³´í†µ")
    df["ì„±ì _score"] = (2*grade_easy + 1*grade_mid) / 100

    return df


def update_preference_scores():
    if ss.catalog is None:
        return
    cat = compute_metric_scores(ss.catalog)
    w = ss.weights
    cat["_pref"] = w["ê³¼ì œ"]*cat["ê³¼ì œ_score"] + w["ì¡°ëª¨ì„"]*cat["ì¡°ëª¨ì„_score"] + w["ì„±ì "]*cat["ì„±ì _score"]
    ss.catalog = cat

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Recommendation & schedules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_recommendations(k=5):
    if ss.catalog is None:
        return pd.DataFrame()
    chosen = set(ss.required)
    for g in ss.groups:
        chosen.update(g["courses"])
    cat = ss.catalog[~ss.catalog[KEY_COL].astype(str).isin(chosen)]
    return cat.sort_values("_pref", ascending=False).head(k)[DISPLAY_COLS+["_pref"]]


def build_schedules(top_k=3):
    if ss.catalog is None:
        return []
    pref = ss.catalog.set_index(KEY_COL)["_pref"].to_dict()
    group_lists = [g["courses"] for g in ss.groups if g["courses"]]
    if not group_lists:
        return []
    combos = []
    for combo in product(*group_lists):
        score = sum(pref.get(c,0) for c in combo) + sum(pref.get(c,0) for c in ss.required)
        combos.append((score, combo))
    combos.sort(reverse=True, key=lambda x: x[0])
    return [(s, list(ss.required)+list(c)) for s,c in combos[:top_k]]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Search helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def trigger_search(target:str, gi:int|None, key:str):
    if ss.catalog is None:
        st.warning("ë¨¼ì € í¸ëŒì„ ë¡œë“œí•˜ì„¸ìš”"); return
    q = ss.get(key, "").strip()
    if not q:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”"); return
    df = ss.catalog
    hits = df[df[KEY_COL].astype(str).str.contains(q, case=False, na=False) | df[NAME_COL].str.contains(q, case=False, na=False)]
    if hits.empty:
        st.info("ì¼ì¹˜í•˜ëŠ” ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤"); return
    ss.search_df = hits[DISPLAY_COLS+["_pref"]]
    ss.search_target = (target, gi)


def select_search_row(i:int):
    row = ss.search_df.iloc[i]; code = row[KEY_COL]
    tgt, gi = ss.search_target
    if tgt == "required":
        if code not in ss.required:
            ss.required.append(code)
    else:
        if code not in ss.groups[gi]["courses"]:
            ss.groups[gi]["courses"].append(code)
    ss.search_df = ss.search_target = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Sidebar â€“ uploads & weights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.header("ğŸ“‚ í¸ëŒ ì—…ë¡œë“œ")
files = st.sidebar.file_uploader("csv / tsv / xlsx", accept_multiple_files=True)
if st.sidebar.button("â¬†ï¸ ë¶ˆëŸ¬ì˜¤ê¸°", disabled=not files):
    load_catalog(files)

st.sidebar.markdown("---")
st.sidebar.subheader("âš–ï¸ ê°€ì¤‘ì¹˜ ì„¤ì •")
for k in ss.weights:
    ss.weights[k] = st.sidebar.number_input(k, value=float(ss.weights[k]), min_value=0.0)
if st.sidebar.button("âœ… ì¬ê³„ì‚°"):
    update_preference_scores()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Required section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.header("ğŸ“Œ í•„ìˆ˜ ê³¼ëª©")
req_key = "req_input"
st.text_input("ì½”ë“œ/ê°•ì˜ëª… ì…ë ¥", key=req_key)
st.button("ğŸ” ê²€ìƒ‰", on_click=trigger_search, args=("required", None, req_key))
for code in ss.required:
    st.write("â€¢", code)

st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Group cards â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("<style>.card{border-radius:12px;padding:1rem;margin-bottom:1rem;}</style>", unsafe_allow_html=True)
for gi, g in enumerate(ss.groups):
    bg = PALETTE[gi % len(PALETTE)]
    with st.container():
        st.markdown(f'<div class="card" style="background:{bg}">', unsafe_allow_html=True)
        g["name"] = st.text_input("ê·¸ë£¹ ì´ë¦„", g["name"], key=f"gname_{gi}")
        for code in g["courses"]:
            st.write("â€¢", code)
        inp = f"gquery_{gi}"
        st.text_input("ì½”ë“œ/ê°•ì˜ëª… ì…ë ¥", key=inp)
        st.button("ğŸ” ê²€ìƒ‰", key=f"gbtn_{gi}", on_click=trigger_search, args=("group", gi, inp))
        st.markdown("</div>", unsafe_allow_html=True)

if st.button("â• ìƒˆ ê·¸ë£¹"):
    ss.groups.append({"name": f"ê·¸ë£¹ {len(ss.groups)+1}", "courses": []})

st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Search overlay â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ss.search_df is not None:
    st.subheader("ê²€ìƒ‰ ê²°ê³¼ â€“ ê³¼ëª© ì„ íƒ")
    for i, r in ss.search_df.reset_index(drop=True).iterrows():
        c = st.columns([5,2,2,1])
        c[0].write(f"{r[NAME_COL]} ({r[KEY_COL]})")
        c[1].write(r[PROF_COL])
        c[2].write(f"ì„ í˜¸ë„ {r['_pref']:.2f}")
        c[3].button("ì„ íƒ", key=f"sel_{i}", on_click=select_search_row, args=(i,))
    st.button("âŒ ë‹«ê¸°", on_click=lambda: (ss.pop("search_df",None), ss.pop("search_target",None)))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Recommendations & schedules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ss.catalog is not None:
    st.subheader("ğŸŒŸ ì¶”ì²œ ê°•ì˜ TOP5")
    st.dataframe(get_recommendations(), hide_index=True)

    st.subheader("ğŸ—“ï¸ ì‹œê°„í‘œ ì œì•ˆ")
    if st.button("ìƒì„±"):
        schedules = build_schedules(3)
        if not schedules:
            st.info("í•„ìˆ˜/ê·¸ë£¹ ê³¼ëª©ì„ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”")
        else:
            for i, (score, codes) in enumerate(schedules, 1):
                st.write(f"### ì•ˆ {i} â€“ í•©ê³„ {score:.2f}")
                st.write(", ".join(codes))
else:
    st.info("ë¨¼ì € í¸ëŒì„ ì—…ë¡œë“œí•˜ì„¸ìš”")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Constraint editor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("â²ï¸ ì œì•½ì¡°ê±´ ì„¤ì •"):
    ss.constraint_open = True
if ss.constraint_open:
    with st.expander("ìš”ì¼/30ë¶„ ë‹¨ìœ„ ì œì•½ì¡°ê±´", True):
        hdr = st.columns(len(DAYS) + 1)
        hdr[0].markdown("**Time**")
        for j, d in enumerate(DAYS):
            hdr[j+1].markdown(f"**{d}")
        slots, cur = [], START
        while cur <= END:
            slots.append(cur.strftime("%H:%M"))
            cur = (datetime.combine(date.today(), cur) + timedelta(minutes=30)).time()
        for t in slots:
            row = st.columns(len(DAYS) + 1)
            row[0].write(t)
            for j, d in enumerate(DAYS):
                key = f"{d}_{t}"
                ch = key in ss.constraints["blocked_slots"]
                if row[j+1].checkbox("", ch, key=key):
                    ss.constraints["blocked_slots"].add(key)
                else:
                    ss.constraints["blocked_slots"].discard(key)
        ss.constraints["must_lunch"] = st.checkbox("12-13ì‹œ ì ì‹¬ ë¹„ìš°ê¸°", value=ss.constraints["must_lunch"])
        if st.button("âœ… ì €ì¥/ë‹«ê¸°"):
            ss.constraint_open = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Debug â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ğŸª› ë””ë²„ê·¸", False):
    st.json({k: str(v)[:200] for k, v in ss.items()})
